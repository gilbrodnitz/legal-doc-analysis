Please review README
Given our intent to move to multi document analysis, should all embedding models run on Ollama?
Latecy is obviously a concern but so is accuracy
We run on Apple Silicon (Macbook Pro M3 Pro)